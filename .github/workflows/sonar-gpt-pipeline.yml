# Security Analysis Pipeline with SonarQube + GPT-4 + Azure Blob Upload
name: Fullstack Security Analysis with SonarQube + GPT-4 + Azure Blob Upload

on:
  workflow_dispatch:
  push:
    branches: [main]

jobs:
  analyze:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup .NET SDK
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '8.x'

      - name: Install SonarScanner and jq
        run: |
          dotnet tool install --global dotnet-sonarscanner
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Begin SonarQube Scan
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
        run: |
          dotnet sonarscanner begin \
            /k:"eshop" \
            /d:sonar.login="${SONAR_TOKEN}" \
            /d:sonar.host.url="${SONAR_HOST_URL}" \
            /d:sonar.verbose=true \
            /d:sonar.exclusions="**/obj/**,**/bin/**,**/*.json,**/BlazorAdmin/**,infra/core/database/sqlserver/**,infra/core/security/keyvault.bicep,infra/core/host/appservice.bicep"

      - name: Clean, Restore and Build
        run: |
          dotnet clean eShopOnWeb.sln
          dotnet restore eShopOnWeb.sln
          dotnet build eShopOnWeb.sln --no-incremental

      - name: End SonarQube Scan
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          dotnet sonarscanner end /d:sonar.login="${SONAR_TOKEN}"

      - name: Wait for SonarQube to finalize
        run: sleep 60

      - name: Create report directory structure
        run: |
          TIMESTAMP=$(date +%Y%m%d)
          mkdir -p report/$TIMESTAMP/gpt-summaries

      - name: Download SonarQube Issues
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
        run: |
          PROJECT_KEY="eshop"
          AUTH_HEADER="Authorization: Basic $(echo -n "${SONAR_TOKEN}:" | base64)"
          HTTP_STATUS=$(curl -s -o sonar-report.json -w "%{http_code}" -H "$AUTH_HEADER" "${SONAR_HOST_URL}/api/issues/search?componentKeys=${PROJECT_KEY}&ps=500")
          if [ "$HTTP_STATUS" -ne 200 ]; then
            echo "ERROR: SonarQube API returned HTTP status $HTTP_STATUS"
            cat sonar-report.json
            exit 1
          fi

      - name: Verify SonarQube Report Content
        run: |
          if [ ! -s sonar-report.json ] || ! jq empty sonar-report.json > /dev/null 2>&1; then
            echo "WARNING: SonarQube report is empty or not valid JSON"
            echo '{"issues":[],"components":[],"total":0}' > sonar-report.json
            echo "Created empty report template"
          fi
          
          # Log report information for diagnostics
          ISSUE_COUNT=$(jq '.issues | length' sonar-report.json)
          COMPONENT_COUNT=$(jq '.components | length' sonar-report.json)
          TOTAL_COUNT=$(jq '.total' sonar-report.json)
          echo "SonarQube report contains: $ISSUE_COUNT issues, $COMPONENT_COUNT components, $TOTAL_COUNT total reported issues"
          
          # Check for empty/incomplete report
          if [ "$ISSUE_COUNT" -eq 0 ]; then
            echo "WARNING: No issues found in SonarQube report. This might cause problems with the GPT analysis."
          fi

      - name: Upload SonarQube Raw Report to Azure Blob
        env:
          AZURE_BLOB_SAS_URL: ${{ secrets.AZURE_BLOB_SAS_URL }}
        run: |
          jq '.' sonar-report.json > sonar-report-pretty.json
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          FILENAME="sonar-report-${TIMESTAMP}.json"
          SAS_URL="${AZURE_BLOB_SAS_URL}"
          BASE_URL=$(echo "$SAS_URL" | cut -d'?' -f1)
          SAS_TOKEN=$(echo "$SAS_URL" | cut -d'?' -f2-)
          FULL_URL="${BASE_URL}/${FILENAME}?${SAS_TOKEN}"
          curl -s -S -f -X PUT "$FULL_URL" -H "x-ms-blob-type: BlockBlob" --data-binary @sonar-report-pretty.json
          
          FOLDER_DATE=$(date +%Y%m%d)
          cp sonar-report-pretty.json "report/${FOLDER_DATE}/${FILENAME}"
          echo "SonarQube report saved to report/${FOLDER_DATE}/${FILENAME}"

      - name: Prepare GPT Payload
        id: prepare-payload
        env:
          AZURE_BLOB_SAS_URL: ${{ secrets.AZURE_BLOB_SAS_URL }}
        run: |
          # Create prompt file with detailed analysis instructions - using the improved prompt
          cat > prompt.txt << 'EOT'
          You are a secure code reviewer with deep knowledge of software vulnerabilities. Given the following static analysis results from SonarQube, perform the following tasks:

          1. Identify the top 10 most severe issues and explain why they are critical.
          2. Group issues by file/module and summarize their overall security and code quality state.
          3. Recommend specific refactoring or remediation actions for the top issues using secure coding best practices.
          4. Present your output in well-structured markdown, including:
             - A prioritized issue summary table
             - A per-module security assessment
             - Actionable recommendations
          EOT

          # Process SonarQube report
          jq '.' sonar-report.json > full-report.json
          jq '.issues // []' full-report.json > issues.json
          jq '.total // 0' full-report.json > total.json
          jq '.components // []' full-report.json > components.json

          # Create GPT payload - using properly quoted jq format
          jq -n \
            --slurpfile issues issues.json \
            --slurpfile total total.json \
            --slurpfile components components.json \
            --rawfile prompt prompt.txt \
            '{"prompt": $prompt, "issues": $issues[0], "total": $total[0], "components": $components[0]}' > gpt-payload.json

          # Validate payload is proper JSON
          if ! jq empty gpt-payload.json > /dev/null 2>&1; then
            echo "ERROR: Generated payload is not valid JSON"
            echo '{"prompt": "Analyze the security issues in this codebase and provide recommendations.", "issues": [], "total": 0, "components": []}' > gpt-payload.json
            echo "Created fallback payload"
          fi

          # Log payload stats
          PAYLOAD_SIZE=$(wc -c < gpt-payload.json)
          ISSUE_COUNT=$(jq '.issues | length' gpt-payload.json)
          echo "GPT payload prepared: $PAYLOAD_SIZE bytes with $ISSUE_COUNT issues"
          
          # Beautify for logging and upload to blob storage
          jq '.' gpt-payload.json > gpt-payload-pretty.json
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          FILENAME="gpt-payload-${TIMESTAMP}.json"
          SAS_URL="${AZURE_BLOB_SAS_URL}"
          BASE_URL=$(echo "$SAS_URL" | cut -d'?' -f1)
          SAS_TOKEN=$(echo "$SAS_URL" | cut -d'?' -f2-)
          FULL_URL="${BASE_URL}/${FILENAME}?${SAS_TOKEN}"
          curl -s -S -f -X PUT "$FULL_URL" -H "x-ms-blob-type: BlockBlob" --data-binary @gpt-payload-pretty.json
          
          FOLDER_DATE=$(date +%Y%m%d)
          cp gpt-payload-pretty.json "report/${FOLDER_DATE}/${FILENAME}"
          echo "GPT payload saved to report/${FOLDER_DATE}/${FILENAME}"

      - name: Call GPT-4 API
        id: call-gpt4
        env:
          GPT_FUNCTION_ENDPOINT: ${{ secrets.GPT_FUNCTION_ENDPOINT }}
          AZURE_BLOB_SAS_URL: ${{ secrets.AZURE_BLOB_SAS_URL }}
        run: |
          # Set environment variables for cleaner code
          GPT_ENDPOINT="${GPT_FUNCTION_ENDPOINT}"
          MAX_RETRIES=3
          SUCCESS=false
          FOLDER_DATE=$(date +%Y%m%d)
          
          echo "Validating payload size before API call..."
          PAYLOAD_SIZE=$(wc -c < gpt-payload.json)
          echo "Payload size: $PAYLOAD_SIZE bytes"
          
          # Set dynamic timeout based on payload size
          if [ "$PAYLOAD_SIZE" -gt 5000000 ]; then
            TIMEOUT=360
            echo "Very large payload detected, setting timeout to $TIMEOUT seconds"
          elif [ "$PAYLOAD_SIZE" -gt 1000000 ]; then
            TIMEOUT=240
            echo "Large payload detected, setting timeout to $TIMEOUT seconds"
          else
            TIMEOUT=120
            echo "Standard payload, setting timeout to $TIMEOUT seconds"
          fi
          
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Making GPT-4 API request (attempt $i of $MAX_RETRIES)"
            # Use verbose flag for debug output but capture both stdout and stderr
            HTTP_CODE=$(curl -v -s -o response.txt -w "%{http_code}" -X POST "$GPT_ENDPOINT" \
              -H "Content-Type: application/json" \
              --data-binary @gpt-payload.json \
              --max-time $TIMEOUT 2> curl_error.txt)
            
            if [ "$HTTP_CODE" -eq 200 ]; then
              SUCCESS=true
              echo "API request successful"
              RESPONSE_SIZE=$(wc -c < response.txt)
              echo "Response size: $RESPONSE_SIZE bytes"
              
              # Save full response for debugging
              cp response.txt "report/${FOLDER_DATE}/gpt-full-response-$(date +%Y%m%d-%H%M%S).txt"
              break
            else
              echo "API request failed with HTTP code $HTTP_CODE (attempt $i)"
              echo "--- Curl error output: ---"
              cat curl_error.txt
              echo "------------------------"
              
              if [ -s response.txt ]; then
                echo "Error response content (first 500 bytes):"
                head -c 500 response.txt
                echo "..."
              fi
              
              # Progressive backoff for retries
              if [ $i -lt $MAX_RETRIES ]; then
                SLEEP_TIME=$(($i * 15))
                echo "Will retry in $SLEEP_TIME seconds..."
                sleep $SLEEP_TIME
              fi
            fi
          done
          
          # Save response regardless of success for debugging
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          FILENAME="gpt-response-${TIMESTAMP}.txt"
          SAS_URL="${AZURE_BLOB_SAS_URL}"
          BASE_URL=$(echo "$SAS_URL" | cut -d'?' -f1)
          SAS_TOKEN=$(echo "$SAS_URL" | cut -d'?' -f2-)
          FULL_URL="${BASE_URL}/${FILENAME}?${SAS_TOKEN}"
          curl -s -S -X PUT "$FULL_URL" -H "x-ms-blob-type: BlockBlob" --data-binary @response.txt
          
          # Process response content
          SUMMARY_FILE="report/${FOLDER_DATE}/gpt-summaries/gpt-summary-${TIMESTAMP}.md"
          
          if [ "$SUCCESS" = true ] && grep -q "^#" response.txt; then
            # Direct markdown response
            cat response.txt > "$SUMMARY_FILE"
            echo "Using markdown response directly"
          elif [ "$SUCCESS" = true ] && grep -q "^{" response.txt; then
            # Try to extract JSON content
            if jq -r '.content // .result // .markdown // .text // .' response.txt > "$SUMMARY_FILE" 2>/dev/null; then
              echo "Extracted content from JSON response"
            else
              echo "# GPT-4 Security Analysis Results" > "$SUMMARY_FILE"
              echo "" >> "$SUMMARY_FILE"
              echo "## Raw API Response" >> "$SUMMARY_FILE"
              echo "" >> "$SUMMARY_FILE"
              echo '```json' >> "$SUMMARY_FILE"
              cat response.txt >> "$SUMMARY_FILE"
              echo '```' >> "$SUMMARY_FILE"
              echo "Failed to extract JSON content, included raw response"
            fi
          else
            echo "# GPT-4 Security Analysis Results" > "$SUMMARY_FILE"
            echo "" >> "$SUMMARY_FILE"
            if [ "$SUCCESS" = true ]; then
              echo "## Raw API Response" >> "$SUMMARY_FILE"
              echo "" >> "$SUMMARY_FILE"
              cat response.txt >> "$SUMMARY_FILE"
              echo "Using raw response content"
            else
              echo "## API Error" >> "$SUMMARY_FILE"
              echo "" >> "$SUMMARY_FILE"
              echo "No valid response was generated. This could be due to API failure." >> "$SUMMARY_FILE"
              echo "" >> "$SUMMARY_FILE"
              echo "### Error Details" >> "$SUMMARY_FILE"
              echo "" >> "$SUMMARY_FILE"
              echo '```' >> "$SUMMARY_FILE"
              cat curl_error.txt >> "$SUMMARY_FILE"
              echo '```' >> "$SUMMARY_FILE"
            fi
          fi
          
          echo "GPT analysis summary saved to $SUMMARY_FILE"
          
          # Also save a local copy for convenience
          cp "$SUMMARY_FILE" "gpt-summary.md"

      - name: Upload GPT-4 Summary to Azure Blob Storage
        env:
          AZURE_BLOB_SAS_URL: ${{ secrets.AZURE_BLOB_SAS_URL }}
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          FILENAME="gpt-summary-${TIMESTAMP}.md"
          SAS_URL="${AZURE_BLOB_SAS_URL}"
          BASE_URL=$(echo "$SAS_URL" | cut -d'?' -f1)
          SAS_TOKEN=$(echo "$SAS_URL" | cut -d'?' -f2-)
          FULL_URL="${BASE_URL}/${FILENAME}?${SAS_TOKEN}"
          curl -s -S -f -X PUT "$FULL_URL" -H "x-ms-blob-type: BlockBlob" --data-binary @gpt-summary.md
          
          echo "Analysis summary has been successfully uploaded to Azure Blob Storage as $FILENAME"
